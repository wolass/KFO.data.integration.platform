Data integration Platform for the KFO
========================================================
author: W. Francuzik
date: 07.04.2021
autosize: true

Why do we need a data integration Platform?
========================================================

The data produced during experiments will have various formats

We can anticipate that the datsets are not going to adhere to one standardized
format:
  - different variable types
  - preferences of data gathering staff
  - insufficient or hard-to-retrive documentation of the datasets
  - messy datasets with lurking variables (using colors or comments)

Types of datasets
=========================================================

- Big data
  - microbiome data
  - miRNA sequencing
  - lncRNA
- small datasets in wet labs
  - ELISA for protein quantification
  - data from FACS
  - qPCR validation data
  - other...

What can we do to avoid errors early
========================================================

1. Gather the data in one place
2. Enforce good documentation
3. Enforce required data formatting
4. Enforce linking to source - labfolder entries with full description of laboratory procedures in case more reference is required in the future.

Proposed solution
========================================================

1. Provide a platform where analysis-ready data can be stored
2. Enforce submitting csv files
3. Automatic analysis of the variables provided
4. Enforce documentation for each file with metadata that would provide the data analysts with basic information about the expected variables and their biological nature

What is possible using this solution?
======================================================

1. Shiny web application available in intranet where a file can be uploaded
2. Verification if the submitted file is a csv file?
3. Verification if variables have proper format
4. Verification of missing data points
5. Provide a standardized questionnaire for each submitted datasate to generate metadata.


